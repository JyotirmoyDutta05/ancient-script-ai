{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8d91d7-e455-40ba-a943-149083c82650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful ✅\n",
      "Data root: /Users/jyotirmoy/Desktop/Image/ancient-script-ai/data\n"
     ]
    }
   ],
   "source": [
    "# Disable TensorFlow (force PyTorch-only)\n",
    "import os\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"All imports successful ✅\")\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
    "print(\"Data root:\", DATA_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d318a8d7-bc88-4822-834a-5e6047fca0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>धर्मो रक्षति रक्षितः</td>\n",
       "      <td>sanskrit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>मी झोपायला जात आहे</td>\n",
       "      <td>marathi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>राम मंदिर बहुत सुंदर है</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>माझे घर मोठे आहे</td>\n",
       "      <td>marathi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>उसका नाम गीता है</td>\n",
       "      <td>hindi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text  language\n",
       "2      धर्मो रक्षति रक्षितः  sanskrit\n",
       "29       मी झोपायला जात आहे   marathi\n",
       "13  राम मंदिर बहुत सुंदर है     hindi\n",
       "20         माझे घर मोठे आहे   marathi\n",
       "15         उसका नाम गीता है     hindi"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        # Sanskrit\n",
    "        \"कर्मणा जायते पुरुषः\", \"ज्ञानं योगेन साध्यते\", \"धर्मो रक्षति रक्षितः\", \"सत्यमेव जयते\", \"विद्या ददाति विनयं\",\n",
    "        \"योगः कर्मसु कौशलम्\", \"अहं ब्रह्मास्मि\", \"तत्त्वमसि\", \"शिवोऽहम्\", \"सर्वं खल्विदं ब्रह्म\",\n",
    "        # Hindi\n",
    "        \"मेरा घर बड़ा है\", \"वह बाज़ार गया था\", \"आज मौसम अच्छा है\", \"राम मंदिर बहुत सुंदर है\", \"मैं स्कूल जा रहा हूँ\",\n",
    "        \"उसका नाम गीता है\", \"मैंने खाना खाया\", \"वह पढ़ाई कर रहा है\", \"यह मेरा दोस्त है\", \"मैं सोने जा रहा हूँ\",\n",
    "        # Marathi\n",
    "        \"माझे घर मोठे आहे\", \"तो बाजारात गेला होता\", \"आज हवा छान आहे\", \"राम मंदिर सुंदर आहे\", \"मी शाळेत जात आहे\",\n",
    "        \"त्याचं नाव गीता आहे\", \"मी जेवलो आहे\", \"तो अभ्यास करत आहे\", \"हा माझा मित्र आहे\", \"मी झोपायला जात आहे\"\n",
    "    ],\n",
    "    \"language\": [\"sanskrit\"]*10 + [\"hindi\"]*10 + [\"marathi\"]*10\n",
    "}\n",
    "\n",
    "lang_df = pd.DataFrame(data)\n",
    "print(\"Dataset size:\", len(lang_df))\n",
    "lang_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059c8341-d492-4612-85e0-be1078396e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       hindi       0.75      1.00      0.86         3\n",
      "     marathi       1.00      0.75      0.86         4\n",
      "    sanskrit       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.92      0.92      0.90         9\n",
      "weighted avg       0.92      0.89      0.89         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    lang_df[\"text\"], lang_df[\"language\"], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Extract character-level features (n-grams)\n",
    "vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(1, 3))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Naive Bayes\n",
    "lang_clf = MultinomialNB()\n",
    "lang_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = lang_clf.predict(X_test_vec)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b33cec-3d9f-4da2-918e-6faf641b479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कर्मणा जायते पुरुषः → sanskrit (1.00)\n",
      "मेरा घर बड़ा है → hindi (1.00)\n",
      "माझे घर मोठे आहे → marathi (1.00)\n"
     ]
    }
   ],
   "source": [
    "def detect_language(text: str):\n",
    "    \"\"\"\n",
    "    Detect language from input text using trained Naive Bayes classifier.\n",
    "    Returns (predicted_language, confidence).\n",
    "    \"\"\"\n",
    "    X = vectorizer.transform([text])\n",
    "    probs = lang_clf.predict_proba(X)[0]\n",
    "    classes = lang_clf.classes_\n",
    "    pred_lang = classes[np.argmax(probs)]\n",
    "    confidence = np.max(probs)\n",
    "    return pred_lang, confidence\n",
    "\n",
    "\n",
    "# Quick test\n",
    "samples = [\"कर्मणा जायते पुरुषः\", \"मेरा घर बड़ा है\", \"माझे घर मोठे आहे\"]\n",
    "for s in samples:\n",
    "    lang, conf = detect_language(s)\n",
    "    print(f\"{s} → {lang} ({conf:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69421eea-7acf-4ae1-b0f0-f7eca9ee5c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: मेरा घर बड़ा है\n",
      "Detected: hindi (1.00)\n",
      "English: My house is big.\n",
      "\n",
      "Text: कर्मणा जायते पुरुषः\n",
      "Detected: sanskrit (1.00)\n",
      "English: Men to be worked:\n",
      "\n",
      "Text: माझे घर मोठे आहे\n",
      "Detected: marathi (1.00)\n",
      "English: My home is large\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"Helsinki-NLP/opus-mt-mul-en\",\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "def translate_text(text, lang):\n",
    "    if lang in [\"hindi\", \"marathi\", \"sanskrit\"]:\n",
    "        result = translator(text, clean_up_tokenization_spaces=True)\n",
    "        return result[0][\"translation_text\"]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "test_sentences = [\"मेरा घर बड़ा है\", \"कर्मणा जायते पुरुषः\", \"माझे घर मोठे आहे\"]\n",
    "\n",
    "for t in test_sentences:\n",
    "    lang, conf = detect_language(t)\n",
    "    translation = translate_text(t, lang)\n",
    "    print(f\"\\nText: {t}\\nDetected: {lang} ({conf:.2f})\\nEnglish: {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a6a528-8045-4ee0-81d0-78453b069a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_text': 'मेरा घर बड़ा है', 'language': np.str_('hindi'), 'confidence': np.float64(1.0), 'translation': 'My house is big.'}\n"
     ]
    }
   ],
   "source": [
    "def full_pipeline(text):\n",
    "    lang, conf = detect_language(text)\n",
    "    if conf < 0.6:\n",
    "        return {\"text\": text, \"status\": \"low_confidence\"}\n",
    "    english = translate_text(text, lang)\n",
    "    return {\n",
    "        \"input_text\": text,\n",
    "        \"language\": lang,\n",
    "        \"confidence\": round(conf, 3),\n",
    "        \"translation\": english\n",
    "    }\n",
    "\n",
    "\n",
    "# Example\n",
    "result = full_pipeline(\"मेरा घर बड़ा है\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5090662b-1c29-48f7-b6dd-9a21f05c31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved models to: /Users/jyotirmoy/Desktop/Image/ancient-script-ai/models\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "models_dir = PROJECT_ROOT / \"models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(lang_clf, models_dir / \"language_id_model.pkl\")\n",
    "joblib.dump(vectorizer, models_dir / \"language_vectorizer.pkl\")\n",
    "\n",
    "print(\"Saved models to:\", models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb09709f-3401-4a61-84c1-141334a48511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ancient-AI)",
   "language": "python",
   "name": "ancient-ai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
