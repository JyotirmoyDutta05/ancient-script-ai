{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda892a8-8e4d-4074-8780-1e972c8b8152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: /Users/jyotirmoy/Desktop/Image/ancient-script-ai/data\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
    "\n",
    "print(\"Data root:\", DATA_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983977af-be61-4ffb-81f7-d77d2148c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 sentences\n"
     ]
    }
   ],
   "source": [
    "# Example: Load Sanskrit or Hindi text\n",
    "sample_corpus = [\n",
    "    \"कर्मणा जायते पुरुषः\",\n",
    "    \"ज्ञानं योगेन साध्यते\",\n",
    "    \"मेरा घर बड़ा है\",\n",
    "    \"वह बाज़ार गया था\",\n",
    "]\n",
    "\n",
    "# Normalize spaces\n",
    "corpus = [re.sub(r'\\s+', ' ', sent.strip()) for sent in sample_corpus]\n",
    "print(\"Loaded\", len(corpus), \"sentences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b702cf-2e90-4239-841d-7d86bf8a175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 29\n",
      "Sample tokens: ['ं', 'ः', 'क', 'ग', 'घ', 'ज', 'ञ', 'ड', 'ण', 'त', 'थ', 'ध', 'न', 'प', 'ब', 'म', 'य', 'र', 'व', 'ष']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    return list(sentence.replace(\" \", \"\"))  # character-level tokens\n",
    "\n",
    "tokens = []\n",
    "for sent in corpus:\n",
    "    tokens.extend(tokenize_sentence(sent))\n",
    "\n",
    "vocab = sorted(set(tokens))\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"Sample tokens:\", vocab[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96cb9b1d-db21-4c95-ac52-cda2692a4d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample bigrams:\n",
      "कर : 1\n",
      "र् : 1\n",
      "्म : 1\n",
      "मण : 1\n",
      "णा : 1\n",
      "ाज : 2\n",
      "जा : 1\n",
      "ाय : 1\n",
      "यत : 2\n",
      "ते : 2\n"
     ]
    }
   ],
   "source": [
    "unigram_counts = Counter(tokens)\n",
    "bigram_counts = Counter(zip(tokens[:-1], tokens[1:]))\n",
    "\n",
    "print(\"Sample bigrams:\")\n",
    "for (a, b), count in list(bigram_counts.items())[:10]:\n",
    "    print(f\"{a}{b} : {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17d0add-e687-46bc-852e-0ef1642ae458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_prob(c1, c2, unigram_counts, bigram_counts, vocab_size, alpha=1):\n",
    "    # P(c2 | c1) = (count(c1,c2) + α) / (count(c1) + α*|V|)\n",
    "    return (bigram_counts[(c1, c2)] + alpha) / (unigram_counts[c1] + alpha * vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2dfd17e-784a-4b8b-8992-1489d54c90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing(sequence, unigram_counts, bigram_counts, vocab):\n",
    "    vocab_size = len(vocab)\n",
    "    best_candidate = None\n",
    "    best_prob = -math.inf\n",
    "\n",
    "    for candidate in vocab:\n",
    "        test_seq = sequence.replace(\"_\", candidate)\n",
    "        total_log_prob = 0.0\n",
    "\n",
    "        for i in range(len(test_seq) - 1):\n",
    "            c1, c2 = test_seq[i], test_seq[i + 1]\n",
    "            prob = bigram_prob(c1, c2, unigram_counts, bigram_counts, vocab_size)\n",
    "            total_log_prob += math.log(prob)\n",
    "\n",
    "        if total_log_prob > best_prob:\n",
    "            best_prob = total_log_prob\n",
    "            best_candidate = candidate\n",
    "\n",
    "    return best_candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e13a43-cb2b-49ea-a84c-2a2e5434fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: क_र्म\n",
      "Predicted missing character: क\n",
      "Reconstructed: ककर्म\n"
     ]
    }
   ],
   "source": [
    "test_seq = \"क_र्म\"\n",
    "pred_char = predict_missing(test_seq, unigram_counts, bigram_counts, vocab)\n",
    "\n",
    "print(f\"Sequence: {test_seq}\")\n",
    "print(f\"Predicted missing character: {pred_char}\")\n",
    "print(f\"Reconstructed: {test_seq.replace('_', pred_char)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df02479d-39c8-4149-9902-dee951b4e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पुषष\n"
     ]
    }
   ],
   "source": [
    "def reconstruct_text_with_missing(text, vocab, unigram_counts, bigram_counts):\n",
    "    for i, ch in enumerate(text):\n",
    "        if ch == \"_\":\n",
    "            pred = predict_missing(text, unigram_counts, bigram_counts, vocab)\n",
    "            text = text.replace(\"_\", pred)\n",
    "    return text\n",
    "\n",
    "print(reconstruct_text_with_missing(\"पु_ष\", vocab, unigram_counts, bigram_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b7258-9755-47a5-b9c5-05f0299b6fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
