{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17227d33-29b4-4419-93d1-e7b3414282e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No input image found. Place Original.jpg or images in 'Input Images/' or provide --input path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    }
   ],
   "source": [
    "# paste into extract_text_from_images.py or into a notebook cell\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Same script as before, but argparse uses parse_known_args() so it won't crash inside Jupyter.\n",
    "\"\"\"\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import exposure\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "\n",
    "# If tesseract isn't on PATH, uncomment and set the path:\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"/usr/bin/tesseract\"\n",
    "\n",
    "def ensure_dirs(*dirs):\n",
    "    for d in dirs:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_input_image(input_path: Path, input_dir: Path):\n",
    "    if input_path and input_path.exists():\n",
    "        img = cv2.imread(str(input_path))\n",
    "        if img is None:\n",
    "            raise RuntimeError(f\"Failed to read image {input_path}\")\n",
    "        return img, str(input_path)\n",
    "    if input_dir.exists():\n",
    "        for f in sorted(input_dir.iterdir()):\n",
    "            if f.suffix.lower() in (\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"):\n",
    "                img = cv2.imread(str(f))\n",
    "                if img is not None:\n",
    "                    return img, str(f)\n",
    "    fallback = Path(\"/Users/jyotirmoy/Desktop/Image/ancient-script-ai/external/tamil_ocr_repo/Input Images/Inscriptions - Wiki1/31.jpg\")\n",
    "    if fallback.exists():\n",
    "        img = cv2.imread(str(fallback))\n",
    "        if img is not None:\n",
    "            return img, str(fallback)\n",
    "    raise FileNotFoundError(\"No input image found. Place Original.jpg or images in 'Input Images/' or provide --input path\")\n",
    "\n",
    "def preprocess(img, denoise=True, adaptive=True):\n",
    "    if img.ndim == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    p2, p98 = np.percentile(gray, (2, 98))\n",
    "    gray = exposure.rescale_intensity(gray, in_range=(p2, p98))\n",
    "    if denoise:\n",
    "        gray = cv2.medianBlur(gray, 3)\n",
    "    if adaptive:\n",
    "        th = cv2.adaptiveThreshold(gray.astype(np.uint8), 255,\n",
    "                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 25, 12)\n",
    "    else:\n",
    "        _, th = cv2.threshold(gray.astype(np.uint8), 0, 255,\n",
    "                              cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    return gray, th\n",
    "\n",
    "def segment_lines(th_img, min_height=12, gap_tol=5):\n",
    "    hp = np.sum(th_img, axis=1)\n",
    "    h = th_img.shape[0]\n",
    "    lines = []\n",
    "    in_line = False\n",
    "    start = 0\n",
    "    empty_rows = 0\n",
    "    for i in range(h):\n",
    "        if hp[i] > 0:\n",
    "            if not in_line:\n",
    "                in_line = True\n",
    "                start = i\n",
    "            empty_rows = 0\n",
    "        else:\n",
    "            if in_line:\n",
    "                empty_rows += 1\n",
    "                if empty_rows >= gap_tol:\n",
    "                    end = i - empty_rows + 1\n",
    "                    if (end - start) >= min_height:\n",
    "                        s = max(0, start - 2)\n",
    "                        e = min(h, end + 2)\n",
    "                        lines.append((s, e))\n",
    "                    in_line = False\n",
    "                    empty_rows = 0\n",
    "    if in_line:\n",
    "        end = h - 1\n",
    "        if (end - start) >= min_height:\n",
    "            s = max(0, start - 2)\n",
    "            e = min(h, end + 2)\n",
    "            lines.append((s, e))\n",
    "    return lines\n",
    "\n",
    "def segment_words_from_line(line_th, kernel_width=40, kernel_height=12, min_area=500):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_width, kernel_height))\n",
    "    dilated = cv2.dilate(line_th, kernel, iterations=1)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if w * h >= min_area:\n",
    "            boxes.append((x, y, w, h))\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "    return boxes, dilated\n",
    "\n",
    "def save_image(path: Path, img):\n",
    "    cv2.imwrite(str(path), img)\n",
    "\n",
    "def main(args):\n",
    "    root = Path('.')\n",
    "    input_dir = root / \"Input Images\"\n",
    "    out_words = root / \"extracted_words\"\n",
    "    out_chars = root / \"extracted_characters\"\n",
    "    ensure_dirs(out_words, out_chars)\n",
    "\n",
    "    input_img_path = Path(args.input) if args.input else None\n",
    "    img, used_path = load_input_image(input_img_path, input_dir)\n",
    "    print(f\"Loaded image: {used_path} shape={img.shape}\")\n",
    "\n",
    "    gray, th = preprocess(img, denoise=True, adaptive=True)\n",
    "    print(\"Preprocessing complete.\")\n",
    "\n",
    "    lines = segment_lines(th, min_height=args.line_min_height, gap_tol=args.line_gap_tol)\n",
    "    print(f\"Detected {len(lines)} lines\")\n",
    "\n",
    "    word_records = []\n",
    "    char_records = []\n",
    "    word_id = 0\n",
    "    char_id = 0\n",
    "\n",
    "    for li, (s, e) in enumerate(lines):\n",
    "        line_th = th[s:e, :]\n",
    "        boxes, dil = segment_words_from_line(line_th,\n",
    "                                             kernel_width=args.kernel_width,\n",
    "                                             kernel_height=args.kernel_height,\n",
    "                                             min_area=args.min_area)\n",
    "        for (x, y, w, h) in boxes:\n",
    "            full_x = x\n",
    "            full_y = s + y\n",
    "            word_crop_inv = th[s + y: s + y + h, x: x + w]\n",
    "            save_img = 255 - word_crop_inv\n",
    "            fname = out_words / f\"word_line{li:02d}_{word_id:04d}.png\"\n",
    "            save_image(fname, save_img)\n",
    "            word_records.append({\n",
    "                \"line\": li,\n",
    "                \"word_id\": word_id,\n",
    "                \"bbox_full\": (int(full_y), int(full_x), int(h), int(w)),\n",
    "                \"file\": str(fname)\n",
    "            })\n",
    "            word_id += 1\n",
    "        print(f\"Line {li}: found {len(boxes)} word(s)\")\n",
    "\n",
    "    for wrec in word_records:\n",
    "        word_path = Path(wrec[\"file\"])\n",
    "        wp = cv2.imread(str(word_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if wp is None:\n",
    "            continue\n",
    "        _, bw = cv2.threshold(wp, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        bw_inv = 255 - bw\n",
    "        contours, _ = cv2.findContours(bw_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        boxes = []\n",
    "        for c in contours:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            if w * h >= args.char_min_area:\n",
    "                boxes.append((x, y, w, h))\n",
    "        boxes = sorted(boxes, key=lambda b: b[0])\n",
    "        for (x, y, w, h) in boxes:\n",
    "            crop = bw[y:y + h, x:x + w]\n",
    "            fname = out_chars / f\"char_{char_id:05d}.png\"\n",
    "            save_image(fname, crop)\n",
    "            char_records.append({\n",
    "                \"word_file\": str(word_path),\n",
    "                \"char_file\": str(fname),\n",
    "                \"bbox\": (int(x), int(y), int(w), int(h))\n",
    "            })\n",
    "            char_id += 1\n",
    "\n",
    "    print(f\"Saved {word_id} words and {char_id} character candidates.\")\n",
    "\n",
    "    ocr_list = []\n",
    "    use_lang = args.lang\n",
    "    for wrec in word_records:\n",
    "        path = wrec[\"file\"]\n",
    "        pil = Image.open(path).convert(\"L\")\n",
    "        arr = np.array(pil)\n",
    "        if arr.mean() < 127:\n",
    "            arr = 255 - arr\n",
    "        pil_for_ocr = Image.fromarray(arr)\n",
    "        try:\n",
    "            if use_lang:\n",
    "                txt = pytesseract.image_to_string(pil_for_ocr, lang=use_lang)\n",
    "            else:\n",
    "                txt = pytesseract.image_to_string(pil_for_ocr)\n",
    "        except Exception as e:\n",
    "            print(\"Tesseract exception:\", e, \"-> retrying without lang\")\n",
    "            txt = pytesseract.image_to_string(pil_for_ocr)\n",
    "        ocr_list.append({\"file\": path, \"text\": txt.strip()})\n",
    "\n",
    "    pd.DataFrame(word_records).to_csv(\"segmented_words.csv\", index=False)\n",
    "    pd.DataFrame(char_records).to_csv(\"segmented_characters.csv\", index=False)\n",
    "    pd.DataFrame(ocr_list).to_csv(\"ocr_results.csv\", index=False)\n",
    "\n",
    "    print(\"Saved segmented_words.csv, segmented_characters.csv, ocr_results.csv\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Extract words/characters/text from images (segmentation + Tesseract OCR)\")\n",
    "    parser.add_argument(\"--input\", \"-i\", help=\"Input image path (optional). If not provided, uses Original.jpg or first image in 'Input Images/'.\")\n",
    "    parser.add_argument(\"--kernel-width\", type=int, default=40, help=\"Morphology kernel width for word segmentation (increase for larger gaps)\")\n",
    "    parser.add_argument(\"--kernel-height\", type=int, default=12, help=\"Morphology kernel height for word segmentation\")\n",
    "    parser.add_argument(\"--min-area\", type=int, default=500, help=\"Minimum area (pixels) to keep a word bounding box\")\n",
    "    parser.add_argument(\"--char-min-area\", type=int, default=30, help=\"Minimum area for character connected-component\")\n",
    "    parser.add_argument(\"--line-min-height\", type=int, default=12, help=\"Minimum height for a line\")\n",
    "    parser.add_argument(\"--line-gap-tol\", type=int, default=5, help=\"Allowed small empty-row gaps inside a line\")\n",
    "    parser.add_argument(\"--lang\", type=str, default=\"tam\", help=\"Language code for tesseract (set to 'tam' for Tamil traineddata). Set empty to use default.\")\n",
    "    # Use parse_known_args so Jupyter kernel args won't break it\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    if args.lang == \"\":\n",
    "        args.lang = None\n",
    "    try:\n",
    "        main(args)\n",
    "    except Exception as exc:\n",
    "        print(\"Error:\", exc)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9263881a-8ad0-4e61-9ee8-8aa0861cdb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ancient-AI)",
   "language": "python",
   "name": "ancient-ai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
