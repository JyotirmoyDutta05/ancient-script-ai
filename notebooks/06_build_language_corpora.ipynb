{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042ffb79-e58b-4b3b-9e3b-fe4d25857444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/jyotirmoy/Desktop/Image/ancient-script-ai\n",
      "SA_ITIHASA_DIR exists: True\n",
      "HI_GENERAL_DIR exists: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports & paths\n",
    "\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import json\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
    "CORPUS_ROOT = DATA_ROOT / \"corpora\"\n",
    "\n",
    "SA_ITIHASA_DIR = CORPUS_ROOT / \"sa_en_itihasa\"\n",
    "HI_GENERAL_DIR = CORPUS_ROOT / \"hi_en_general\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"SA_ITIHASA_DIR exists:\", SA_ITIHASA_DIR.exists())\n",
    "print(\"HI_GENERAL_DIR exists:\", HI_GENERAL_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94458c47-0f8b-4a0f-8b04-fb2cee515872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dev.sn\n",
      "Reading test.sn\n",
      "Reading train.sn\n",
      "Total Sanskrit characters: 9191388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'तस्यां चीरं वसानायां नाथवत्यामनाथवत्। प्रचुक्रोश जनः सर्वो धिक् त्वां दशरथं त्विति ॥\\nतेन तत्र प्रणादेन दुःखितः स महीपतिः। चिच्छेद जीविते श्रद्धां धर्मे यशसि चात्मनः॥ स निःश्वस्योष्णमैक्ष्वाकस्तां भार्यामिदमब्रवीत्। कैकेयि कुशचीरेण न सीता गन्तुमर्हति॥\\nसुकुमारी च बाला च सततं च सुखोचिता। नेयं वनस्य योग्येति सत्यमाह गुरुर्मम ॥\\nइयं हि कस्यापि करोति किंचित् तपस्विनी राजवरस्य पुत्री। या चीरमासाद्य वनस्य मध्ये जाता विसंज्ञा श्रमणीव काचित्॥\\nचीराण्यपास्याज्जनकस्य कन्या नेयं प्रतिज्ञा मम दत्तपूर्वा। यथासुख'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2: load Sanskrit corpus into memory as one big string\n",
    "\n",
    "def load_sanskrit_corpus(sa_dir: Path):\n",
    "    \"\"\"Load all Sanskrit text from the itihasa files.\"\"\"\n",
    "    texts = []\n",
    "\n",
    "    # Case 1: paired .sn files (train.sn, dev.sn, test.sn)\n",
    "    sn_files = sorted(sa_dir.glob(\"*.sn\"))\n",
    "    if sn_files:\n",
    "        for f in sn_files:\n",
    "            print(\"Reading\", f.name)\n",
    "            texts.append(f.read_text(encoding=\"utf-8\"))\n",
    "    else:\n",
    "        # Case 2 (fallback): maybe you converted to CSV later\n",
    "        # You can fill this in when/if you make sa_en_itihasa/*.csv files\n",
    "        raise FileNotFoundError(\"No .sn files found in sa_en_itihasa. Check folder.\")\n",
    "\n",
    "    full_text = \"\\n\".join(texts)\n",
    "    print(\"Total Sanskrit characters:\", len(full_text))\n",
    "    return full_text\n",
    "\n",
    "sa_text = load_sanskrit_corpus(SA_ITIHASA_DIR)\n",
    "sa_text[:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42954db0-28dd-45ce-99d2-25d181b2abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 48047 unique 3-grams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('तस्', 16338),\n",
       " ('स्य', 32726),\n",
       " ('्या', 38474),\n",
       " ('यां', 5453),\n",
       " ('ांच', 3576),\n",
       " ('ंची', 24),\n",
       " ('चीर', 191),\n",
       " ('ीरं', 455),\n",
       " ('रंव', 1168),\n",
       " ('ंवस', 362),\n",
       " ('वसा', 666),\n",
       " ('सान', 1690),\n",
       " ('ाना', 13841),\n",
       " ('नाय', 1018),\n",
       " ('ाया', 4012),\n",
       " ('ांन', 1967),\n",
       " ('ंना', 1771),\n",
       " ('नाथ', 485),\n",
       " ('ाथव', 168),\n",
       " ('थवत', 105)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: build character n-gram counts (for reconstruction)\n",
    "\n",
    "def build_char_ngrams(text: str, n: int = 3):\n",
    "    counts = collections.Counter()\n",
    "    cleaned = \"\".join(text.split())  # remove whitespace for pure char stream\n",
    "\n",
    "    for i in range(len(cleaned) - n + 1):\n",
    "        gram = cleaned[i:i+n]\n",
    "        counts[gram] += 1\n",
    "\n",
    "    print(f\"Built {len(counts)} unique {n}-grams\")\n",
    "    return counts\n",
    "\n",
    "sa_char_trigrams = build_char_ngrams(sa_text, n=3)\n",
    "list(sa_char_trigrams.items())[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "803e168c-f86f-4eca-92bb-4fbff91cef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 1046260\n",
      "Unique words: 296342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('तस्यां', 164),\n",
       " ('चीरं', 5),\n",
       " ('वसानायां', 1),\n",
       " ('नाथवत्यामनाथवत्', 1),\n",
       " ('प्रचुक्रोश', 3),\n",
       " ('जनः', 123),\n",
       " ('सर्वो', 56),\n",
       " ('धिक्', 38),\n",
       " ('त्वां', 1080),\n",
       " ('दशरथं', 20),\n",
       " ('त्विति', 7),\n",
       " ('तेन', 1286),\n",
       " ('तत्र', 2715),\n",
       " ('प्रणादेन', 1),\n",
       " ('दुःखितः', 38),\n",
       " ('स', 10613),\n",
       " ('महीपतिः', 159),\n",
       " ('चिच्छेद', 259),\n",
       " ('जीविते', 46),\n",
       " ('श्रद्धां', 9)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Sanskrit word frequencies\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenize_words(text: str):\n",
    "    # simple split on whitespace + punctuation\n",
    "    tokens = re.split(r\"\\s+|[।॥,.?!;:\\\"'()\\[\\]{}]\", text)\n",
    "    tokens = [t for t in tokens if t.strip()]\n",
    "    return tokens\n",
    "\n",
    "sa_words = tokenize_words(sa_text)\n",
    "print(\"Total tokens:\", len(sa_words))\n",
    "\n",
    "sa_word_freq = collections.Counter(sa_words)\n",
    "print(\"Unique words:\", len(sa_word_freq))\n",
    "list(sa_word_freq.items())[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b9f0bf-2e07-402c-9b30-bba9a49db024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('कर्म', 990),\n",
       " ('कर्मणा', 405),\n",
       " ('कर्माणि', 194),\n",
       " ('कर्मसु', 71),\n",
       " ('कर्मणः', 63)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5: suggestion function for reconstruction\n",
    "\n",
    "def suggest_similar(prefix: str, word_freq: collections.Counter, top_k: int = 10):\n",
    "    \"\"\"Return top_k most frequent words that start with the given prefix.\"\"\"\n",
    "    candidates = [(w, c) for w, c in word_freq.items() if w.startswith(prefix)]\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    return candidates[:top_k]\n",
    "\n",
    "# Example:\n",
    "suggest_similar(\"कर्म\", sa_word_freq, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6906581a-6810-4517-9a0c-85718497aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/jyotirmoy/Desktop/Image/ancient-script-ai/models/sa_char_trigrams.json\n",
      "Saved: /Users/jyotirmoy/Desktop/Image/ancient-script-ai/models/sa_word_freq.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: save to models/ for reuse\n",
    "\n",
    "MODELS_ROOT = PROJECT_ROOT / \"models\"\n",
    "MODELS_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "# Save n-grams as JSON\n",
    "with open(MODELS_ROOT / \"sa_char_trigrams.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sa_char_trigrams, f, ensure_ascii=False)\n",
    "\n",
    "# Save word frequencies as JSON\n",
    "with open(MODELS_ROOT / \"sa_word_freq.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sa_word_freq, f, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved:\", MODELS_ROOT / \"sa_char_trigrams.json\")\n",
    "print(\"Saved:\", MODELS_ROOT / \"sa_word_freq.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e680fb-fe40-4f4d-8aff-1b134289898a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
